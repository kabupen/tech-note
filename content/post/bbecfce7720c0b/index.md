+++
title = '『これからの強化学習』を読んで'
date = 2025-10-19T08:40:25+09:00
draft = false
categories = []
tags = []
+++


### 添字



### 報酬

報酬は
$$
R_{t+1} = r(S_t, A_t, S_{t+1})
$$
の報酬関数によって定義されます。報酬は“遷移”に対して支払われる量であるので、どういった遷移（$s_t \to s_{t+1}$）なのかにも依存します。




### 価値関数

価値観数は収益（ある将来の期間の報酬の和）の期待値として定義されます。

$$
V^\pi(s) = E_\pi [G_t | S_t = s]
$$


### Sarsa

現在地（$$S_t$$）から次の状態へ遷移（$$S_{t+1}$$）するときに更新をかける方法です。

$$
Q(S_t, A_t) \leftarrow Q_(S_t, A_t) + \alpha (R_{t+1} + \gamma Q(S_{t+1}, A_{t+1}) - Q(S_t, A_t))
$$

1. 現在の状態 $$S_t$$ を観測
2. 方策から行動 $$A_t$$ を選択
3. $$A_t$$ を実行、環境が $$R_{t+1}$$ と $$S_{t+1}$$ を返す
4. 次の状態 $$S_{t+1}$$ からの行動 $$A_{t+1}$$ を選択
5. sarsa の更新式を実行